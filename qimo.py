import jieba
import requests
import stopwords
import streamlit as st
from streamlit_echarts import st_echarts
from collections import Counter
import re
import string
from bs4 import BeautifulSoup
from langdetect import detect
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from io import BytesIO
import base64

# å®šä¹‰æ•°æ®æ¸…æ´—å‡½æ•°
def clean_text(text):
    text = text.replace('\n', '')
    text = text.replace(' ', '')
    text = text.strip()
    return text


# å®šä¹‰åˆ†è¯å‡½æ•°
def segment_chinese(text):
    stopwords = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'è¿™', 'é‚£', 'ä¹‹', 'ä¸', 'å’Œ', 'æˆ–', 'è™½ç„¶',
                 'ä½†æ˜¯', 'ç„¶è€Œ', 'å› æ­¤']
    punctuation = "ã€ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šâ€œâ€â€˜â€™~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ã€ã€‘ï½›ï½+-*/=ã€Šã€‹<>ã€Œã€ã€ã€ã€ã€‘ã€”ã€•ï½Ÿï½ Â«Â»â€œâ€â€˜â€™'':;,/\\|[]{}()$^"
    text = text.translate(str.maketrans("", "", punctuation)).replace('\n', '')
    words = jieba.lcut(text)
    words = [word for word in words if word not in stopwords]
    return words


def segment_english(text):
    stopwords = set(stopwords.words('english'))
    words = re.findall(r'\b\w+\b', text.lower())
    words = [word for word in words if word not in stopwords and word not in string.punctuation]
    return words


# ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œæ•°å­—
def remove_punctuation(text):
    punctuation = string.punctuation
    text = text.translate(str.maketrans('', '', punctuation))
    return re.sub('\d+', '', text)


# ç§»é™¤HTMLæ ‡ç­¾
def remove_html_tags(text):
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)


# ä»HTMLä¸­æå–æ­£æ–‡æ–‡æœ¬
def extract_body_text(html):
    soup = BeautifulSoup(html, 'html.parser')
    text = soup.find('body').get_text()
    return text


# ç”Ÿæˆè¯äº‘å›¾
def generate_wordcloud(words):
    wordcloud = WordCloud(font_path ="C:/Windows/Fonts/msyh.ttc",width=800, height=400, background_color='white').generate(' '.join(words))
    return wordcloud


def main():
    st.set_page_config(page_title="ç½‘é¡µæ–‡æœ¬åˆ†æå·¥å…·", page_icon="ğŸ“Š", layout="wide")

    st.title("ğŸ“Š ç½‘é¡µæ–‡æœ¬åˆ†æå·¥å…·")
    st.write("è¯·è¾“å…¥ä¸€ä¸ªç½‘é¡µé“¾æ¥ï¼Œæˆ‘ä»¬å°†ä¸ºæ‚¨æå–å…¶ä¸­çš„æ–‡æœ¬ï¼Œå¹¶å±•ç¤ºè¯é¢‘ç»Ÿè®¡å›¾ã€‚")

    url = st.text_input('è¾“å…¥ç½‘é¡µé“¾æ¥:', '')

    if st.button('å¼€å§‹åˆ†æ'):
        if url:
            st.write("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™...")
            try:
                r = requests.get(url)
                r.encoding = 'utf-8'
                text = r.text
                text = extract_body_text(text)
                text = remove_html_tags(text)
                text = remove_punctuation(text)
                text = clean_text(text)

                # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                language = detect(text)
                if language == 'zh-cn':
                    words = segment_chinese(text)
                else:
                    words = segment_english(text)

                word_counts = Counter(words)
                top_words = word_counts.most_common(20)

                # ç”ŸæˆæŸ±çŠ¶å›¾
                bar_options = {
                    "tooltip": {
                        "trigger": 'item',
                        "formatter": '{b} : {c}'
                    },
                    "xAxis": [{
                        "type": "category",
                        "data": [word for word, count in top_words],
                        "axisLabel": {
                            "interval": 0,
                            "rotate": 30
                        }
                    }],
                    "yAxis": [{"type": "value"}],
                    "series": [{
                        "type": "bar",
                        "data": [count for word, count in top_words]
                    }]
                }

                st.subheader("è¯é¢‘æŸ±çŠ¶å›¾")
                st_echarts(bar_options, height='500px')

                # ç”Ÿæˆè¯äº‘å›¾
                st.subheader("è¯äº‘å›¾")
                wordcloud = generate_wordcloud(words)
                fig, ax = plt.subplots()
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig)

                st.success("åˆ†æå®Œæˆï¼")
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {e}")
        else:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥")


if __name__ == "__main__":
    main()
